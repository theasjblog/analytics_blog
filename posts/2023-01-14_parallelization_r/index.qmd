---
title: "Make any R code faster with this parallelization trick"
description: "A handy R trick to run in parallel different workflows."
date: "2023-01-14"
categories: [r]
---
![Photo by Bernd Dittrich on Unsplash.](img/cover.jpg)
# What will you learn?

A technique to parallelize different functions. The technique overcomes two limitations of R and the parallel packages:

- R is a single-threaded language. By default, it can only run one command at a time.
- `parallel` and similar packages allow running only **one function** in parallel, and not different functions.

## When does this apply?

Letâ€™s consider these two use cases:

![(A) calls the same function `foo` repeatedly. (B) calls different functions: `foo_1`, `foo_2`, and `foo_3`.](img/when_apply.png)


The two scenarios might look identical, but there is a critical difference between them. While (A) executes teh same funciton over and over again, (B) executes three different functions.

(A) is the classic use case for parallelization, and documented solutions exist. (B) is harder to parallelize because parallelization is usually designed for a single function.

Today, we will learn how to parallelize problem (B). In general, the pattern applies to any workflow where multiple, independent logic streams converge at a single aggregation point. Some practical examples include:

- Calling different models for comparison or aggregating predictions.
- Running different functions over files in I/O operations.

## Traditional Parallelization

Let's start by solving problem (A) using non-parallelized code:

```{r, eval=FALSE}
# Define slow function
foo <- function(n){
  Sys.sleep(1)
  return(n+1)
}

# Call the slow function multiple times
myNum <- 10

# Non-parallel execution
microbenchmark::microbenchmark({
  for(i in 1:myNum){
    res <- foo(i)
  }
}, times = 10)
# Mean is ~9.86s
```

We will now use `parallel::parLapply()` to optimize this code:

```{r, eval=FALSE}
# Define cluster
cl <- parallel::makeCluster(5)
parallel::clusterExport(cl, 'foo')

microbenchmark::microbenchmark({
  res <- parallel::parLapply(cl, seq(1, myNum), function(d){
    foo(d)
  })
}, times = 10)
# Mean is ~1.98s

parallel::stopCluster(cl)
```

We create a cluster of 5, meaning `foo()` is called 5 times simultaneously. The execution time decreases to ~2s.

## The Problem We Solve Today

What if we need to run multiple functions (`foo1`, `foo2`, `foo3`) in parallel?

Here is the non-parallel version:

```{r, eval=FALSE}
# Define 3 slow functions
foo1 <- function(n){
  Sys.sleep(1)
  return(n+1)
}

foo2 <- function(n){
  Sys.sleep(1)
  return(n*2)
}

foo3 <- function(n){
  Sys.sleep(1)
  return(n^2)
}

# Non-parallel execution
microbenchmark::microbenchmark({
  res1 <- foo1(4)
  res2 <- foo2(4)
  res3 <- foo3(4)
}, times = 10)
# Mean is ~2.95s
```

### The Solution

Instead of looping over numbers, we loop over function calls using `parallel::parLapply()` as we did before, but we first create a list of functions to dispatch to the different workers:

```{r, eval=FALSE}
# Wrap functions into a list
parallelFunctions <- list(
  f1 = function(n){foo1(n)},
  f2 = function(n){foo2(n)},
  f3 = function(n){foo3(n)}
)

cl <- parallel::makeCluster(3)
parallel::clusterExport(cl, c('foo1', 'foo2', 'foo3'))

microbenchmark::microbenchmark({
  res <- parallel::parLapply(cl, parallelFunctions, function(d){
    d(4)
  })
}, times = 10)
# Mean is ~0.99s

parallel::stopCluster(cl)
```

This reduces execution time from ~3s to under 1s, allowing us to run different functions in parallel.

## A Quick Side Note

Each parallelized call runs in its own environment, meaning global variables, functions, and libraries must be explicitly exported. This overhead can sometimes negate the benefits of parallelization.

For this reason, I rarely parallelize exploratory scripts. Instead, I parallelize APIs or Shiny apps where the cluster is created at startup, ensuring a smooth user experience.

### Final Thoughts

Before parallelizing, focus on optimizing your code through good design. For more on R parallelization, check the official documentation for `parallel` and `doParallel`.

I hope this trick is helpful! Let me know if you use different approaches to solve this problem.

Thanks for reading!

