{
  "hash": "2e00dd7a88daa7c54df6e1197575f2d7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Make any R code faster with this parallelization trick\"\ndescription: \"A handy R trick to run in parallel different workflows.\"\ndate: \"2023-01-14\"\ncategories: [r]\n---\n\n\n![Photo by Bernd Dittrich on Unsplash.](img/cover.jpg)\n# What will you learn?\n\nA technique to parallelize different functions. The technique overcomes two limitations of R and the parallel packages:\n\n- R is a single-threaded language. By default, it can only run one command at a time.\n- `parallel` and similar packages allow running only **one function** in parallel, and not different functions.\n\n## When does this apply?\n\nLetâ€™s consider these two use cases:\n\n![(A) calls the same function `foo` repeatedly. (B) calls different functions: `foo_1`, `foo_2`, and `foo_3`.](img/when_apply.png)\n\n\nThe two scenarios might look identical, but there is a critical difference between them. While (A) executes teh same funciton over and over again, (B) executes three different functions.\n\n(A) is the classic use case for parallelization, and documented solutions exist. (B) is harder to parallelize because parallelization is usually designed for a single function.\n\nToday, we will learn how to parallelize problem (B). In general, the pattern applies to any workflow where multiple, independent logic streams converge at a single aggregation point. Some practical examples include:\n\n- Calling different models for comparison or aggregating predictions.\n- Running different functions over files in I/O operations.\n\n## Traditional Parallelization\n\nLet's start by solving problem (A) using non-parallelized code:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define slow function\nfoo <- function(n){\n  Sys.sleep(1)\n  return(n+1)\n}\n\n# Call the slow function multiple times\nmyNum <- 10\n\n# Non-parallel execution\nmicrobenchmark::microbenchmark({\n  for(i in 1:myNum){\n    res <- foo(i)\n  }\n}, times = 10)\n# Mean is ~9.86s\n```\n:::\n\n\n\nWe will now use `parallel::parLapply()` to optimize this code:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define cluster\ncl <- parallel::makeCluster(5)\nparallel::clusterExport(cl, 'foo')\n\nmicrobenchmark::microbenchmark({\n  res <- parallel::parLapply(cl, seq(1, myNum), function(d){\n    foo(d)\n  })\n}, times = 10)\n# Mean is ~1.98s\n\nparallel::stopCluster(cl)\n```\n:::\n\n\n\nWe create a cluster of 5, meaning `foo()` is called 5 times simultaneously. The execution time decreases to ~2s.\n\n## The Problem We Solve Today\n\nWhat if we need to run multiple functions (`foo1`, `foo2`, `foo3`) in parallel?\n\nHere is the non-parallel version:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define 3 slow functions\nfoo1 <- function(n){\n  Sys.sleep(1)\n  return(n+1)\n}\n\nfoo2 <- function(n){\n  Sys.sleep(1)\n  return(n*2)\n}\n\nfoo3 <- function(n){\n  Sys.sleep(1)\n  return(n^2)\n}\n\n# Non-parallel execution\nmicrobenchmark::microbenchmark({\n  res1 <- foo1(4)\n  res2 <- foo2(4)\n  res3 <- foo3(4)\n}, times = 10)\n# Mean is ~2.95s\n```\n:::\n\n\n\n### The Solution\n\nInstead of looping over numbers, we loop over function calls using `parallel::parLapply()` as we did before, but we first create a list of functions to dispatch to the different workers:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wrap functions into a list\nparallelFunctions <- list(\n  f1 = function(n){foo1(n)},\n  f2 = function(n){foo2(n)},\n  f3 = function(n){foo3(n)}\n)\n\ncl <- parallel::makeCluster(3)\nparallel::clusterExport(cl, c('foo1', 'foo2', 'foo3'))\n\nmicrobenchmark::microbenchmark({\n  res <- parallel::parLapply(cl, parallelFunctions, function(d){\n    d(4)\n  })\n}, times = 10)\n# Mean is ~0.99s\n\nparallel::stopCluster(cl)\n```\n:::\n\n\n\nThis reduces execution time from ~3s to under 1s, allowing us to run different functions in parallel.\n\n## A Quick Side Note\n\nEach parallelized call runs in its own environment, meaning global variables, functions, and libraries must be explicitly exported. This overhead can sometimes negate the benefits of parallelization.\n\nFor this reason, I rarely parallelize exploratory scripts. Instead, I parallelize APIs or Shiny apps where the cluster is created at startup, ensuring a smooth user experience.\n\n### Final Thoughts\n\nBefore parallelizing, focus on optimizing your code through good design. For more on R parallelization, check the official documentation for `parallel` and `doParallel`.\n\nI hope this trick is helpful! Let me know if you use different approaches to solve this problem.\n\nThanks for reading!\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}