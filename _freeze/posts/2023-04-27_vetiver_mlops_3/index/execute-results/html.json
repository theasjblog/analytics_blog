{
  "hash": "e08d8c61302a06070a73b8dc7f3793b7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Build an end-to-end MLOps solution with vetiver for R and Python - Part 2\"\ndescription: \"The feedback loop: monitoring.\"\ndate: \"2023-04-27\"\ncategories: [\"mlops\"]\n---\n\n\n![Image by the author.](./img/cover.png)\n\nThis is the third article in [a series about building an MLOps solution using the vetiver R (and Python) package](../2023-04-13_vetiver_mlops_1/index.qmd). I suggest reading the first part before continuing with this article.\n\n### Introduction\n\nIn the previous articles, we explored how to design a viable MLOps solution using (almost) only the R ecosystem. We then developed a model and a deployment pipeline to make it available through a REST API. Now that our model is ready to serve the business, we need to monitor it. This article will focus on monitoring the model.\n\n### Overview\n\nWhen software fails, there are clear signs. A service becomes unreachable, an error message is displayed, or some other form of reporting manifests itself.\n\nModels fail silently. They simply start to return inaccurate answers. Until a subject matter expert looks at the predictions made, those errors will go undetected. Furthermore, models failures can have catastrophic repercussions for the business. We need to monitor our models.\n\nThere are several things we might want to monitor:\n\n* Technical: response time, load, reachability of the model API, etc.\n* Business: inputs and outputs. This allows us to verify that there is no data drift (input monitoring) and that the predictions have the expected distribution (output monitoring). If we have access to the ground truth, we can also compare it with the predictions to assess the accuracy of our model.\n\nThe best way to monitor models is through an interactive dashboard that allows us to drill down on details. Shiny is a well-known dashboard-building framework that we can use for this purpose.\n\nWe will be building a very simple dashboard. In fact, it is way too simple for production purposes, but it will be enough to give us a feeling of the effort required to build such a system.\n\n### Architecture\n\nThe monitoring app displays aggregated logs. If there are several thousand calls to the models, it is not feasible for the app to digest the logs on-demand. Instead, there should be a third component that pre-processes the logs and stores them somewhere accessible (e.g., a database, pins, a blob storage).\n\nIn our example, we use a manually-run script to do this step. In real life, you can convert the script to a scheduled R Markdown deployed on rsconnect. The schedule will depends on the nature of your model. If your model is only hit once a week, there is little value in having an hourly schedule.\n\n![The app generates raw logs stored in a dedicated folder. An R Markdown aggregates the logs and stores the output as pins. The monitor app automatically picks up refreshed pins and displays the aggregated logs to the user. Boxes in blue represent code components, boxes in green represent storage components.](./img/workflow.png)\n\n### Create the logs\n\nBefore we can analyze the logs, we need to create some logs. We will simulate some traffic to the API using a script.\n\nWe first make sure the model API is running by executing the bash script `./auxScripts/startAPI.bash`. Once the API is running, we can call the R script `./auxScript/prepare_logs_for_monitoring.R`. This script will take about 10 minutes to run, and it will create 3 new log folders:\n\n* `./logs/requests` to log requests.\n* `./logs/responses` to log responses.\n* `./log/performance` to log response times.\n\nThe logs are generated from the `keep-out` dataset. Each folder will have three files, each one corresponding to a different date.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#THIS WILL TAKE A FEW MINUTES (5 to 10min)  \n# start the plumber from auxScripts/startAPI.bash first  \n########################  \nboard <- pins::board_local()  \n  \n# OPTIONAL: clean logs  \nfor (i in c('requests', 'responses','performance')){  \n  unlink(here::here('logs', i), force = TRUE, recursive = TRUE)  \n  dir.create(here::here('logs', i))  \n}  \n# call the model with the keep-out data we saved  \nkeep_out <- board %>% pins::pin_read('keep_out')  \n# split it into three to mock 3 different days. Each day has ~1/3 of the data  \nset.seed(222)  \ndata_split <- initial_split(keep_out, prop = .33)  \ndays <- list()  \ndays$day1 <- training(data_split)  \ntmpDf  <- testing(data_split)  \ndata_split <- initial_split(tmpDf, prop = .5)  \ndays$day2 <- training(data_split)  \ndays$day3  <- testing(data_split)  \n# loop through the 3 days datasets  \nfor(i in 1:3){  \n  for (k in seq(1:nrow(days[[i]]))){  \n    preds <- httr::POST(\"<http://127.0.0.1:4023/predict_flights>\",  \n                        body = jsonlite::toJSON(days[[i]][k,]),  \n                        encode = \"json\")  \n  }  \n  # rename the log files to change the data. Our processing script will use  \n  # the file name to guess the date, rather than the timestamp in the logs  \n  file.rename(here::here('logs', 'requests',  \n                         paste0(as.character(Sys.Date()), '.log')),  \n              here::here('logs', 'requests',  \n                         paste0(as.character(Sys.Date()+i), '.log')))  \n  file.rename(here::here('logs', 'responses',  \n                         paste0(as.character(Sys.Date()), '.log')),  \n              here::here('logs', 'responses',  \n                         paste0(as.character(Sys.Date()+i), '.log')))  \n  file.rename(here::here('logs', 'performance',  \n                         paste0(as.character(Sys.Date()), '.log')),  \n              here::here('logs', 'performance',  \n                         paste0(as.character(Sys.Date()+i), '.log')))  \n}\n```\n:::\n\n\n\n### Log pre-processing script\n\nOur pre-processing is minimal. We parse the logs and convert the content to a dataframe.\n\nNote that we save the processed logs to pins. This is unlikely a good choice in real-world applications. You will want to use a database instead. This will make searching the logs easier. In real-world, you might also need to consider data access implications if your logs contain any personal information.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get logs of calls  \npinLogData <- function(logType, board){  \n  # list all the available log files  \n  # note that in a prod env you will not save the logs in the same folder  \n  # where the app files are  \n  allLogFiles <- list.files(here::here('logs', logType))  \n  allLogData <- list()  \n  # extract the info from each log file  \n  for(i in seq_along(allLogFiles)){  \n    readF <- read_file(here::here('logs', logType, allLogFiles[i]))  \n    # parse  \n    readF <- unlist(  \n               stringr::str_split(  \n                 readF,  \n                 'INFO \\\\\\\\\\\\\\\\\\[[0-9]*-[0-9]*-[0-9]* [0-9]*:[0-9]*:[0-9]*\\\\\\\\\\\\\\\\\\]\\\\\\\\\\\\\\\\\\[[0-9]*\\\\\\\\\\\\\\\\\\] '  \n               )  \n             )  \n    readF <- readF[nchar(readF)>0]  \n    readF <- lapply(readF, function(d){jsonlite::fromJSON(d)})  \n    readF <- bind_rows(readF)  \n    readF$dateIs <- as.Date(stringr::str_replace(allLogFiles[i], '.log', ''))  \n    allLogData[[i]] <- readF  \n  }  \n  allLogData <- bind_rows(allLogData)  \n  \n  board %>% pins::pin_write(allLogData, logType)  \n  return(invisible(NULL))  \n}  \n  \npinLogData('requests', board)  \npinLogData('responses', board)  \npinLogData('performance', board)\n```\n:::\n\n\n\n### The monitoring app\n\nThe monitoring app displays data from the logs and metadata from the vetiver model.\n\nFrom the metadata:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmetadata <- unlist(board %>% pins::pin_meta('flights_fit'))  \nmodel_versions <- board %>% pins::pin_versions('flights_fit')`\n```\n:::\n\n\n\nFrom the logs:\n\n* Distribution of predictions.\n* Number of times the model has been called.\n* Accuracy plot. The keep-out dataset included the ground truth. We use it to calculate accuracy.\n* Response time plot.\n\nYou can find the full code for the app in the repo.\n\nThere are a few key things to discuss about the app. The more important ones are about the choice of Shiny rather than flexdashboard and the scalability of the solution.\n\n### Why a Shiny app?\n\n`{vetiver}` provides a basic monitoring app with the command `vetiver_dashboard()`. However, this is a `{flexdashboard}`. Personally, I dislike `{flexdashboard}`, and I will never recommend it for production purposes. I have never seen a well-built `{flexdashboard}`. They lead to a single, long, and unmaintainable file, and they are not as testable as Shiny apps.\n\nTherefore, I went for a Shiny app. The Shiny app I provide as an example is by no means production-ready. But it is more manageable than a `{flexdashboard}`.\n\n> If you want to know what it takes to make the app professional-grade, you can have a look at [these articles](../2022-10-16_build_professional_shiny_1/index.qmd).\n\nNote that our monitoring app is not really an app: it is more a report at this stage. There is no interactivity with the dashboard. A real-life solution will enable logs exploration and drill-down through interactivity.\n\n### Scalability\n\nThis app is designed as a monitoring tool for our model. But what if we have several models? Do we create an app for each model? Do we create an uber dashboard with links to the dedicated dashboards?\n\nThese are very important questions that need to be considered while we start to plan our own fully-fledged MLOps solution.\n\n### Wrap up\n\nIn this article we put together a monitoring app for our MLOps solution. Our goal was to have a tool that can warn us if anything starts to go wrong.\n\nThe app is functional, but extremely rough. There is a lot of work to be done to bring it to production-grade and to make it scalable.\n\n### Coming next\n\nIn the next and last article of this series, we will have our retrospective meeting. We have now built a rudimentary end-to-end MLOps solution using the vetiver package, so we are well positioned to comment on what works well and what the limitations are. These information will help us determine if the effort was worth it, if it even makes sense to build a vetiver-based MLOps solution.\n\n# Links\n\n* [Part 1 of the series](../2023-04-13_vetiver_mlops_1/index.qmd)",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}