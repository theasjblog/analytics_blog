{
  "hash": "9778c8bf96fa61a55d1997144f5e300b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Everything you want to know about the R apply functions\"\ndescription: \"Use cases, examples, benchmarking.\"\ndate: \"2022-08-21\"\ncategories: [r, apply]\n---\n\n\n![](img/cover.png)\n\n## What is the apply family?\n\n`for` loops are the joy and the curse of any developer. They are instinctive to write, as they are a direct representation of how we think. “Go over this vector and apply this function to each column” becomes `for (i in myVec){myFun(i)}`. Yet, `for` loops are inefficient and ugly. Being ugly is not just an aesthetic problem: it is a readability and maintainability problem.\n\nSo how can we drop for loops, or at least most of them? How can we make our code faster and more readable?\n\nEnter the apply family.\n\nThe apply family is part of base R. No need to install any extra package to use them. The apply functions simplify applying a set of operations to vectors, data frames, matrices, or lists. And of course, apply functions are significantly faster than a for loop.\n\nThe apply family has several members:\n\n* apply\n* lapply\n* tapply\n* mapply\n* vapply\n* sapply\n* replicate\n\nLet’s have a look at all of them in detail. I will give you examples, use cases, and benchmarking. I will also talk about limitations and why you should be avoiding some of them.\n\n## apply\n\n`apply` works with data frames or matrices, but not vectors or lists. The normal use case for this function is when you have tabular data, and you want to apply some operation across all rows or all columns. Its syntax is:\n\n`apply(X, MARGIN, FUN, …, simplify = TRUE)`\n\nWhere:\n* **X**. The input data.\n* **MARGIN**. Apply the function FUN to rows (MARGIN=1) or columns (MARGIN=2).\n* **FUN**. It is the function apply uses across rows or columns.\n* **simplify**. In most cases it forces the results to be a list, if TRUE. We will see more examples later.\n\n### apply examples\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# the data frame\nmyDf <- data.frame(item1=c(1,2),\n                   item2=c(3,4),\n                   item3=c(5,6))\n                   \n# apply the function mean across rows\napply(X = myDf, MARGIN = 1, FUN = mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3 4\n```\n\n\n:::\n\n```{.r .cell-code}\n# apply the function mean across columns\napply(X = myDf, MARGIN = 2, FUN = mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nitem1 item2 item3 \n  1.5   3.5   5.5 \n```\n\n\n:::\n:::\n\n\n\nIn both cases, the input is a data frame, but the output is a numeric vector. In the second example, the output is a named numeric vector because the columns in the data frame have names.\n\n### Using a custom function\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# the data frame\nmyDf <- data.frame(item1=c(1,2),\n                   item2=c(3,4),\n                   item3=c(5,6))\n\n# custom function\nmyFun <- function(d){\n  return(d^2)\n}\n\napply(myDf, 1, myFun)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1] [,2]\nitem1    1    4\nitem2    9   16\nitem3   25   36\n```\n\n\n:::\n:::\n\n\n\n\nThis time our output is a matrix. This is because the function `myFun` is not aggregating data as the function `mean` did.\n\nWe could use a one-liner by replacing `myFun` inside the `apply` call with its definition. I advise against that. Declaring `myFun` separately enables testing that is independent from the apply function.\n\n### The simplify argument\n\nThe output of the apply function can be a matrix of a vector, with dimensions derived from a combination of the input class and dimension, and output of the FUN function. Using an aggregation function as mean over a list with three elements returns a vector of length three. We can force apply to always return a list by setting `simplify=FALSE`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# the data frame\nmyDf <- data.frame(item1=c(1,2),\n                   item2=c(3,4),\n                   item3=c(5,6))\n\napply(myDf, 2, mean, simplify=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nitem1 item2 item3 \n  1.5   3.5   5.5 \n```\n\n\n:::\n\n```{.r .cell-code}\napply(myDf, 2, mean, simplify=FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$item1\n[1] 1.5\n\n$item2\n[1] 3.5\n\n$item3\n[1] 5.5\n```\n\n\n:::\n:::\n\n\n\nIn the first example (`simplify=TRUE`) the output is a vector, in the second (`simplify=FALSE`) it is a list. The default behaviour is `simplify=TRUE`.\n\n### Benchmarking apply\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\n\n# prepare data\nn <- 1e1\nmyDf <- as.data.frame(lapply(seq(n), function(d){runif(n)}))\nmyFun <- function(d){d^2}\n\n# apply across rows\nsummary(microbenchmark(\n  res <- apply(myDf, 1, myFun), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 58.65501\n```\n\n\n:::\n\n```{.r .cell-code}\n# for loop across rows\nres <- matrix(nrow=n, ncol=n)\nsummary(microbenchmark(\n  for (i in 1:n){\n    res[i,] <- myFun(as.numeric(myDf[i,]^2))\n  }, unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3940.775\n```\n\n\n:::\n\n```{.r .cell-code}\n# apply across columns\nsummary(microbenchmark(\n  apply(myDf, 2, myFun), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 47.91998\n```\n\n\n:::\n\n```{.r .cell-code}\n# for loop across columns\nres <- matrix(nrow=n, ncol=n)\nsummary(microbenchmark(\n  for (i in 1:3){\n    res[,i] <- myFun(as.numeric(myDf[,i]^2))\n  }, unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 983.1009\n```\n\n\n:::\n:::\n\n\n\n\nAs we can see, `apply` is orders of magnitude faster than a `for` loop.\n\n### apply considerations\n\nThe output of `apply` is not guaranteed. It depends on the size and type of the input, and on the output of FUN. Having an unreliable output makes the function not recommendable to build software. We would need to add several validations to check that the input and the output are what we expect. At the very least, we would have to remember to set `simplify=FALSE`.\n\n## lapply\n\n`lapply` is a very versatile function. It works on lists, data frames, and vectors. Its syntax is:\n\n`lapply(X, FUN, …)`\n\n### lapply examples\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# prepare data\nmyLs <- list(a = seq(5,8),\n             b = seq(2,4))\nmyDf <- data.frame(item1=c(1,2),\n                   item2=c(3,4),\n                   item3=c(5,6))\nmyVc <- seq(1,3)\n\n# lapply on lists\nlapply(myLs, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$a\n[1]  148.4132  403.4288 1096.6332 2980.9580\n\n$b\n[1]  7.389056 20.085537 54.598150\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply on data frames\nlapply(myDf, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$item1\n[1] 2.718282 7.389056\n\n$item2\n[1] 20.08554 54.59815\n\n$item3\n[1] 148.4132 403.4288\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply on vectors\nlapply(myVc, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] 2.718282\n\n[[2]]\n[1] 7.389056\n\n[[3]]\n[1] 20.08554\n```\n\n\n:::\n:::\n\n\n\nNote how the output is always a list, regardless of the input.\n\n### Benchmarking lapply\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\n# prepare the data\nn <- 1e1\nmyLs <- lapply(seq(1,n), function(d){runif(n)})\nmyDf <- as.data.frame(lapply(seq(1,n), function(d){runif(n)}))\n\n######################\n# lapply vs for loop #\n######################\n# lapply on lists\nsummary(microbenchmark(\n  res <- lapply(myLs, exp), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.11765\n```\n\n\n:::\n\n```{.r .cell-code}\n# for loop on lists\nres <- list()\nsummary(microbenchmark(\n  for(i in 1:n){\n    res[[i]] <- exp(myLs[[i]])\n  }, unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 803.1552\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply on data frame\nsummary(microbenchmark(\n  res <- lapply(myDf, exp), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.22998\n```\n\n\n:::\n\n```{.r .cell-code}\n# for loop on data frame\nres <- list()\nsummary(microbenchmark(\n  for(i in 1:n){\n    res[[i]] <- exp(myLs[[i]])\n  }, unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 798.5349\n```\n\n\n:::\n\n```{.r .cell-code}\n###################\n# apply vs lapply #\n###################\n# apply\nsummary(microbenchmark(\n  apply(myDf, 2, FUN=exp, simplify = FALSE), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 39.43544\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply\nsummary(microbenchmark(\n  lapply(myDf, exp), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.20497\n```\n\n\n:::\n\n```{.r .cell-code}\n## [1] 3.46655\n```\n:::\n\n\n\n\n`lapply` is significantly faster than both the `for` loop and the `apply` function.\n\n### lapply considerations\n\nI use `lapply` very often. One thing that I particularly like is that I know that the output will be a list. We could use `apply` with `simplify=FALSE`, but, as we saw, it is slower than `lapply`. Furthermore, `apply` does not work on lists.\n\n## tapply\n\n`tapply` creates grouped summaries, where the groups are given by factors. Its syntax is:\n\n`tapply(X, INDEX, FUN=NULL, …, default=NA, simplify=TRUE)`\n\nWhere:\n\n* **INDEX**. These are the factors. It has the same length of X.\n* **default**. It is the default output of FUN if no value is present for a given factor.\n\n### tapply examples\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nJane  Joe \n 704  760 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Joe Jane Mark \n 655  805   NA \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Joe Jane Mark \n 655  805    0 \n```\n\n\n:::\n:::\n\n\n\n### Benchmarking tapply\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\nlibrary(dplyr)\n# prepare the data\nn <- 1e3\nsales <- sample(seq(10, 20), n, replace = TRUE)\nseller <- factor(sample(LETTERS, n, replace = TRUE))\nmyDf <- data.frame(sales = sales, seller = seller)\n\n#######################\n# tapply  vs for loop #\n#######################\n# tapply\nsummary(microbenchmark(\n  tapply(sales, seller, sum, default=0), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 31.72539\n```\n\n\n:::\n\n```{.r .cell-code}\n# for loop\nsummary(microbenchmark(\n  for(i in levels(seller)){\n    sum(sales[seller==i])\n  }, unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 959.9248\n```\n\n\n:::\n\n```{.r .cell-code}\n#############################################\n# tapply  vs for dplyr                      #\n#                                           #\n# Of course the above method is quite crude.#\n# A better way to summarize would leverage  #\n# dplyr machinery instead.                  #\n#############################################\n# tapply\nsummary(microbenchmark(\n  tapply(sales, seller, sum, default=0), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 31.65569\n```\n\n\n:::\n\n```{.r .cell-code}\n# dplyr\nsummary(microbenchmark(\n  myDf %>% group_by(seller) %>% summarize(sum(sales)), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1144.237\n```\n\n\n:::\n:::\n\n\n\n`tapply` is faster than a `for` loop. What is perhaps surprising is that, at least in our example, `tapply` is also faster than `dplyr`. This shows the importance of profiling our code.\n\nInterestingly, `dplyr` is also slower than a `for` loop. However, one thing to consider is code readability. The `dplyr` syntax is much cleaner and easier to understand than the for loop.\n\nOne important note on the difference between `dplyr` and `tapply`: if a factor has no data, `dplyr` will not give us its summary.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The seller 'Mark' has no sales. Mark is a level in the seller vector, \n# but he has no data entry.\nsales <- sample(seq(10, 20), 100, replace = TRUE)\nseller <- factor(sample(c('Joe', 'Jane'), 100, replace = TRUE), \n                 levels = c('Joe', 'Jane', 'Mark'))\ndf <- data.frame(sales = sales, seller = seller)\n\ntapply(sales, seller, sum, default=0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Joe Jane Mark \n 664  880    0 \n```\n\n\n:::\n\n```{.r .cell-code}\ndf %>% \n  group_by(seller) %>% \n  summarize(sum(sales))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  seller `sum(sales)`\n  <fct>         <int>\n1 Joe             664\n2 Jane            880\n```\n\n\n:::\n:::\n\n\n\n“Mark” is not present in the `dplyr` results, but he is in the `tapply` results.\n\n### tapply considerations\n\n`tapply` is a convenient and fast alternative to `dplyr` when we need to summarize data by factors. If we are concerned about controlling `tapply` output’s class, we can set `simplify=FALSE`.\n\n## sapply\n\n`sapply` is a wrapper of `lapply`. Its syntax is:\n\n`sapply(X, FUN, …, simplify=TRUE, USE.NAMES=TRUE)`\n\nIn particular, `sapply(X, FUN, simplify=FALSE, USE.NAMES=FALSE)` is equivalent to `lapply(X, FUN)`.\n\n### Comparison between sapply and lapply\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# prepare data\n# in this list a and b have equal length\nmyLsSame <- list(a = seq(1,5),\n                 b = seq(6,10))\n# in this list a and have different length\nmyLsDifferent <- list(a = seq(1,5),\n                      b = seq(1,3))\nmyDf <- data.frame(a = seq(1,5),\n                  b = seq(6,10))\n\n###########################\n# on lists of same lenght #\n###########################\n# sapply\nsapply(myLsSame, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              a          b\n[1,]   2.718282   403.4288\n[2,]   7.389056  1096.6332\n[3,]  20.085537  2980.9580\n[4,]  54.598150  8103.0839\n[5,] 148.413159 22026.4658\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply\nlapply(myLsSame, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$a\n[1]   2.718282   7.389056  20.085537  54.598150 148.413159\n\n$b\n[1]   403.4288  1096.6332  2980.9580  8103.0839 22026.4658\n```\n\n\n:::\n\n```{.r .cell-code}\n################################\n# on lists of different lenght #\n################################\n# sapply\nsapply(myLsDifferent, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$a\n[1]   2.718282   7.389056  20.085537  54.598150 148.413159\n\n$b\n[1]  2.718282  7.389056 20.085537\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply\nlapply(myLsDifferent, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$a\n[1]   2.718282   7.389056  20.085537  54.598150 148.413159\n\n$b\n[1]  2.718282  7.389056 20.085537\n```\n\n\n:::\n\n```{.r .cell-code}\n##################\n# on data frames #\n##################\n# sapply\nsapply(myDf, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              a          b\n[1,]   2.718282   403.4288\n[2,]   7.389056  1096.6332\n[3,]  20.085537  2980.9580\n[4,]  54.598150  8103.0839\n[5,] 148.413159 22026.4658\n```\n\n\n:::\n\n```{.r .cell-code}\n# sapply, but setting simplify=FALSE\nsapply(myDf, exp, simplify = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$a\n[1]   2.718282   7.389056  20.085537  54.598150 148.413159\n\n$b\n[1]   403.4288  1096.6332  2980.9580  8103.0839 22026.4658\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply\nlapply(myDf, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$a\n[1]   2.718282   7.389056  20.085537  54.598150 148.413159\n\n$b\n[1]   403.4288  1096.6332  2980.9580  8103.0839 22026.4658\n```\n\n\n:::\n:::\n\n\n\n\nLet’s unpack the above. `lapply` is consistent. Whether it is processing a `data frame` or a `list`, it returns a `list`. `sapply` is all over the place. If it processes a `data frame` or a `list` where all elements have the same length, then it will return a `matrix`. Unless we specify `simplify=FALSE`, which causes it to return a `list`. On the other hand, if the input is a `list` where the elements have different lengths, then it will return a `list`.\n\n### Benchmarking sapply\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\n# prepare data\nn <- 1e3\nmyLs <- lapply(seq(1,n), function(d){runif(n)})\n\n# sapply, simplify=FALSE\nsummary(microbenchmark(\n  sapply(myLs, exp, simplify = FALSE), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3850.034\n```\n\n\n:::\n\n```{.r .cell-code}\n# sapply, simplify=TRUE\nsummary(microbenchmark(\n  sapply(myLs, exp, simplify = TRUE), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7586.005\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply\nsummary(microbenchmark(\n  lapply(myLs, exp), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3735.209\n```\n\n\n:::\n:::\n\n\n\n`sapply` is slow when we use `simplify=TRUE`. `lapply` is faster than `sapply` when `simplify=FALSE`.\n\n### sapply considerations\n\nI do not recommend `sapply`. Its performance is almost identical to `lapply`, but worse, and its lack of full control over the output can cause problems.\n\n## vapply\n\nIt is a safer version of `sapply`, as its output is controlled. Its syntax is:\n\n`vapply(X, FUN, FUN.VALUE, …, USE.NAMES=TRUE)`\n\nWhere:\n\n* **FUN.VALUE**. This argument describes the output of FUN. This is what gives great control over the behaviour of vapply. We’ll see what this means in the examples below.\n\n### vapply examples\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# prepare data\nmyDf <- data.frame(a = seq(1,5),\n                   b = seq(6,10))\n# length(a) == length(b)\nmyLsSame <- list(a = seq(1,5),\n                 b = seq(6,10))\n# length(a) != length(b)\nmyLsDifferent <- list(a = seq(1,10),\n                      b = seq(6,10))\n             \n# vapply on data frames\nvapply(myDf, exp, rep(double(1),5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              a          b\n[1,]   2.718282   403.4288\n[2,]   7.389056  1096.6332\n[3,]  20.085537  2980.9580\n[4,]  54.598150  8103.0839\n[5,] 148.413159 22026.4658\n```\n\n\n:::\n\n```{.r .cell-code}\n# Note that the function exp returns a double, so we use \n# double(1) for FUN.VALUE. Also, the data frame columns \n# have 5 rows, so FUN will return 5 doubles. Hence, \n# the complete declaration of FUN.VALUE must repeat double(1)\n# 5 times: rep(double(1), 5)\n\n# vapply on lists of same length\nvapply(myLsSame, exp, rep(double(1),5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              a          b\n[1,]   2.718282   403.4288\n[2,]   7.389056  1096.6332\n[3,]  20.085537  2980.9580\n[4,]  54.598150  8103.0839\n[5,] 148.413159 22026.4658\n```\n\n\n:::\n\n```{.r .cell-code}\n# vapply on lists of different length\ntryCatch({\n  vapply(myLsDifferent, exp, rep(double(1), 10))\n},\nerror = function(msg){msg})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<simpleError in vapply(myLsDifferent, exp, rep(double(1), 10)): values must be length 10,\n but FUN(X[[2]]) result is length 5>\n```\n\n\n:::\n:::\n\n\n\n`vapply` fails when the elements in the list have different lengths. This is because FUN.VALUE cannot deal with changing outputs of FUN.\n\n### Benchmarking vapply\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\n# prepare the data\nn <- 1e3\nmyLs <- lapply(seq(1,n), function(d){runif(n)})\n\n# vapply\nsummary(microbenchmark(\n  vapply(myLs, exp, FUN.VALUE = rep(double(1), n)), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4816.96\n```\n\n\n:::\n\n```{.r .cell-code}\n# sapply\nsummary(microbenchmark(\n  sapply(myLs, exp, simplify = FALSE), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3364.196\n```\n\n\n:::\n\n```{.r .cell-code}\n# lapply\nsummary(microbenchmark(\n  lapply(myLs, exp), unit='microseconds'\n))$mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3631.638\n```\n\n\n:::\n:::\n\n\n\n\n`lapply` is the faster option, followed by `sapply` and `vapply`.\n\n### vapply considerations\n\n`vapply` is a good alternative to `lapply` when you need to be absolutely sure about the input and the output, even at the expense of performance. If you need more flexibility, for instance because you cannot expect all items in the list to have the same length, then use `lapply` instead.\n\n## mapply\n\n`mapply` is yet another version of sapply. It is its multivariate implementation. `mapply` syntax is:\n\n`mapply(FUN, …, MoreArgs=NULL, SIMPLIFY=TRUE, USE.NAMES=TRUE)`\n\n### mapply examples\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create lists\nmapply(rep, times = 1:4, x = 4:1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] 4\n\n[[2]]\n[1] 3 3\n\n[[3]]\n[1] 2 2 2\n\n[[4]]\n[1] 1 1 1 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# times and x are arguments to the rep function. \n# mapply is taking the first element in x (4), \n# and it applies rep the first element of times: rep(4, 1). \n#It then moves to the second elements of x and \n# times: rep(3, 2), and so on.\n\nmapply(rep, times = 1:4, MoreArgs = list(x = 42))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] 42\n\n[[2]]\n[1] 42 42\n\n[[3]]\n[1] 42 42 42\n\n[[4]]\n[1] 42 42 42 42\n```\n\n\n:::\n\n```{.r .cell-code}\n# As above, but this time we repeat the number 42 for the specified times.\n\nmyFun <- function(x, y){seq_len(x) + y}\nmapply(myFun,\n       c(it1 =  1, it2 = 2, it3 = 3),\n       c(it1 = 10, it2 = 0, it3 = -10))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$it1\n[1] 11\n\n$it2\n[1] 1 2\n\n$it3\n[1] -9 -8 -7\n```\n\n\n:::\n\n```{.r .cell-code}\n# In this case, at the first iteration we take the first \n# element of the first vector as x, and the first element \n# of the second vector (10) as y. We then repat for all \n# three elements in the vectors.\n\n# operations across vectors\nv1 <- sample(seq(1,10), 5)\nv2 <- sample(seq(1,10), 5)\nmapply(max, v1, v2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  4 10 10  9  4\n```\n\n\n:::\n\n```{.r .cell-code}\nmapply(function(x,y){x+y}, v1, v2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  5 18 13 17  5\n```\n\n\n:::\n\n```{.r .cell-code}\n# create matrices\nmapply(rep, rep(NA, 3), times=5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3]\n[1,]   NA   NA   NA\n[2,]   NA   NA   NA\n[3,]   NA   NA   NA\n[4,]   NA   NA   NA\n[5,]   NA   NA   NA\n```\n\n\n:::\n:::\n\n\n\n## replicate\n\nAnother `sapply` wrapper. replicate allows for repeated evaluation of an expression. Its syntax is:\n\n`replicate(n, expr, simplify = \"array\")`\n\n### replicate examples\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreplicate(5, mean(rexp(10)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8870014 0.9267021 0.4255634 1.3004241 0.9574433\n```\n\n\n:::\n\n```{.r .cell-code}\n#Note how this is different from rep:\nrep(mean(rexp(10)), 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5451531 0.5451531 0.5451531 0.5451531 0.5451531\n```\n\n\n:::\n\n```{.r .cell-code}\n# With replicate we generate a random number 5 times, \n# with rep we generate a random number once, then repeat it 5 times.\n```\n:::\n\n\n\n## Wrap up\n\nThe apply family is a fairly large one. It offers several options to handle different data structures, and we can be more or less flexible on our output.\n\nI hope this overview of the apply family gave you some ideas on how to improve your code and remove some for loops.\n\nBelow, I have included a table to help you decide which function you should use in different scenarios.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}